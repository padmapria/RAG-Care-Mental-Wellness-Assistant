# RAG-Care-Mental-Wellness-Assistant

## Table of Contents
- [Project Overview](#project-overview)
- [Problem Description](#problem-description)
- [Technologies](#technologies)
- [Knowledge Base](#knowledge-base)
- [Ground Truth Generation and Evaluation](#ground-truth-generation-and-evaluation)
- [RAG Flow](#rag-flow)
- [Ingestion Pipeline](#ingestion-pipeline)
- [Retrieval Evaluation](#retrieval-evaluation)
- [RAG Evaluation](#rag-evaluation)
- [Containerization](#containerization)
- [FlaskAPI](#flaskapi)
- [Monitoring](#monitoring)
- [Reproducibility](#reproducibility)
- [Setup Instructions](#setup-instructions)
- [Usage](#usage)
- [CI/CD Pipeline](#ci-cd-pipeline)

## Project Overview
The **RAG-Care-Mental-Wellness-Assistant** project aims to develop a conversational AI system that provides accessible mental wellness support. By leveraging Retrieval-Augmented Generation (RAG) technology, the assistant allows users to interact with trusted mental health resources effectively.

## Problem Description
Traditional methods of retrieving mental health information can be time-consuming and inefficient. This project addresses the challenge of navigating complex mental health resources by providing fast, personalized, and accurate responses to users' mental health-related queries.

## Technologies
- **Python**: Core programming language.
- **Hugging Face Transformers**: For language model integration.
- **LLaMA Models (LLaMA3:8b & Gemma2:2b)**: For ground truth query generation and evaluation.
- **LLaMA Models (Gemma2 & OpenAI3.5 and OpenAI4o)**: For RAG Flow evaluation and 
- **Pydantic**: Data modeling and validation.
- **Pandas**: Data manipulation and analysis.
-  **ElasticSearch**: Vectorstore
- **Flask**: Web application framework.
- **MySQL**: Data storage of user interaction
- **Grafana**: Dashboard
- **Docker**: For containerization and environment management.
- **CI/CD**: Unit/Integration test, GitHub Actions, and CD via AWS.

---

# Section 1: Dataset and Ground Truth Generation  <br/>
(present in the folder /notebooks/step0_data_preparation.ipynb)  <br/>
 
## Knowledge Base
- **Counsel Chat Dataset**: A comprehensive dataset of mental health-related conversations.
- **Source**: Utilizes the [Counsel Chat Dataset](https://huggingface.co/datasets/nbertagnolli/counsel-chat) from Hugging Face.
- **Focus**: Data related to **depression**.
- **Processing**: Only questions with depression as the topic and titles longer than 20 characters are included.


## Ground Truth Generation and Evaluation
- **LLaMA3** and **Gemma2 models** are utilized for generating high-quality ground truth data, ensuring that the response is accurate and relevant to mental wellness queries on depression.
- Ground truth data is evaluated before testing with RAG. **LLaMA3** evaluates the quality of queries generated by **Gemma2**, and vice versa, to ensure robustness and relavence of the query.

---

# Section 2: RAG Flow and Evaluation   <br/>
(present in the folder /notebooks/step0_data_preparation.ipynb) <br/>

Integrates the Counsel Chat Dataset knowledge base and **LLaMA3:8b, OpenAI API, Gemma2:2b models** 

## Ingestion Pipeline
- Semi-automated ingestion pipeline via **Jupyter Notebook (step0)** for data ingestion and preparation

## Indexing and Storing the data
 **VectorStore**: The project integrates **Elasticsearch** to index and retrieve mental health-related data, enabling efficient vector similarity searches for question-answer pairs.
 
## Retrieval Evaluation
The system evaluates retrieval performance using:
- `minsearch_search` (text search)
- `question_answer_vector_knn` (vector search)
- `question_answer_vector_knn_combined` (vector + text search)

#### Evaluation Metrics
- **Hit Rate**: Measures the proportion of relevant documents retrieved.
- **Mean Reciprocal Rank (MRR)**: Assesses the ranking quality of retrieved documents.

## RAG Evaluation
- The RAG flow is evaluated using **Gemma2** and **OpenAI** as LLM judges for:
- Relvevence of LLM generated answer against true answer
- Relvevence of LLM generated answer against the question

## User query rewriting 
- The user queries are rewritten with openAI 3.5 turbo API
---

# Section 3: Interface  <br/>
## Containerization
- The entire system is containerized using **Docker** and managed via **docker-compose** to ensure ease of deployment.
- The docker compose file is present in the root directory of the project
---
(present in the folder /services/app)  <br/>
## FlaskAPI
- A web application built with **Flask**,
- The application provides the following functionalities:
  - Query Processing: Accepts user queries and rewrites them to optimize search results.
  - Vector Store Search: Searches the vector store to retrieve relevant answers.
  - LLM Integration: Utilizes two Large Language Models (LLMs):
  - Generator LLM: Retrieves answers from the vector store.
  - Evaluator LLM: Calculates the effectiveness of the retrieved answer and provides relevance explanations using OpenAI LLM.
```
http://localhost:5000/ask
```
  - Feedback Processing: Accepts feedback for every query
```
http://localhost:5000/feedback
```
---

## Monitoring
- **User feedback collection**: Tracks user interaction and feedback with MySQL.
```
http://localhost:3306
```

- **Monitoring dashboard**: Provides insights into system performance and user activity.
- The application also integrates Grafana, a  monitoring and visualization tool. Grafana allows users to track performance metrics of the RAG model and the underlying infrastructure, ensuring that the application operates efficiently.
-  Grafana dashboard can be accessed from :

```
http://localhost:3000
```
---

## Reproducibility
- The project ensures reproducibility with clear setup instructions and an accessible dataset.
---

## Setup Instructions
1. Clone the repository.
2. Install the required dependencies using `pip install -r requirements.txt`.
3. Run **Jupyter Notebook (notebooks folder)** for data ingestion and processing, RAG evaluation
4. Use `docker-compose up` to start the end to end Flask based RAG application
```
docker compose up -d
```
---

## Usage
1. Access the web application at [http://localhost:5000](http://localhost:5000).
2. Input mental wellness-related queries.
3. Receive personalized guidance and support from trusted mental health resources.

---

## CI/CD Pipeline
- Utilizes **GitHub Actions** for continuous integration and deployment, ensuring that the system is always up-to-date and functional.
